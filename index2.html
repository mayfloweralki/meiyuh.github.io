<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body bgcolor="white">
 <title> Mei-Yuh Hwang, speech recognition, machine translation, language understanding, scene-text OCR, GenAI </title>
 
<img src="datou.jpg" height=150> <br>
<h3> Mei-Yuh Hwang, IEEE Fellow</h3> 

<font size="-1"> <a href="https://www.ece.uw.edu/people/mei-yuh-hwang/">Affiliate Professor at EE Department </a> 
     </font> <br>
<font size="-1"> University of Washington  (UW) </font> <br>
 
 <p>
 Mei-Yuh received her PhD in Computer Science from Carnegie Mellon University in 1993 and had worked at Microsoft in the U.S. and in China for 20 years, 
 publishing numerous conference and journal papers, and delivering industry products in speech recognition, machine translation, and 
 language understanding.
  
  <p> Additionally she spent four years at University of Washington on Mandarin speech recognition and four years at an AI startup,
   <a href="http://www.mobvoi.com">Mobvoi</a>, 
   focusing on AI smart watches and personal assistants. Her focus has been always on turning state-of-the-art technologies 
   into end-users' hands.  She is an IEEE fellow, who is passionate in bridging the gap between academia and industry. 
  

  <h3> Work experiences
       
<table border="1">
 <tr> <td> Meta <br> 5/2022--present <td> AI Research Scientist <br> Bellevue WA
  <td> <ul>
 <li> <a href="https://en.wikipedia.org/wiki/Scene_text">Scene-Text OCR</a>
 <li> Text-to-image generation.
  </ul>
  
 <tr> <td> Microsoft<br> 4/2020-4/2022 <td> Partner science manager <br> Bellevue WA
  <td> 
   <ul>
    <li>
   NLP for Outlook and Teams search, based on fine-tuning on, and/or few-shot prompting to, 
   various large pre-trained language models.
     <li> GPT Copilot prompt engineering for manipulating Excel spreadsheets
   </ul>
   
   <tr> <td> Mobvoi AI Lab <br> 2016-2020 <td> Director <br> Redmond, WA <td> 

    <ul>
     <li>
<a href="http://www.mobvoi.com">Mobvoi</a> makes speech-enabled 
smart IoT
devices</a>, from hardware to software, all in-house.
 <li> We are one of the most successful companies in <a href="http://store.ticwear.com">smart watches</a> in China. 
 <li> Mobvoi also provides the in-car voice assistant for VW automobiles in China.
 The technology includes both on-the-cloud and on-device voice navigation, enabling majority of assistant functionalities without internet connection.
 <li> Though a young small company
that focuses on industry products, we are actively participating in
our speech research community. 
<!-- Our publications can be found in <a href="mobvoi/index.html#pub"> Mobvoi publications</a>. -->
  <ul>

  <tr> <td> Microsoft China <br>  2012-2015 <td> Principal science manager <br> Beijing & Suzhou
   <td> 
    <ul>
 <li> Speech recognition and language understanding for Cortana.
<p> To deliver non-English Cortana without human annotated data,
Mei-Yuh designed
an adapted translation algorithm which
offered both paraphrasing and generalization capabilities
with required semantic slot tags. 
The protoype model was further improved via
 iterative data augmentation using RNN and newly logged data.
 
<li>Microsoft cognitive services on Azure cloud:
<ul>
<li> Cortana non-English language
understanding for  <a href="https://azure.microsoft.com/en-us/services/cognitive-services/language-understanding-intelligent-service/">LUIS</a>, 
<li> Language-model adaptation for
<a href="https://azure.microsoft.com/en-us/services/cognitive-services/custom-speech-service/">customized speech recognition</a>.
<li> Spontaneous 
speech recogition for
<a href="https://www.techlicious.com/blog/skype-translator-preview-app-launch/">Skype speech-to-speech translation</a>.
</ul>
</ul>

<tr> <td> Microsoft and UW <br> 1994-2012 <td> Principal scientist
 <td>
 <ul>
 <li> Machine translation, Microsoft, Redmond WA, 2008-2012.
Mei-Yuh co-built Bing Translator automated training infrastructure,
including the design and implementation of 
 map-reduce parallel processing, based on <a href="https://www.microsoft.com/en-us/research/project/dryadlinq/">DryadLink</a>.
She further designed and implemented
<a href="https://hub.microsofttranslator.com/">
 Bing Translation Hub</a> for customized vertical-domain translation.
  
 <li> Speech recognition at Univ. of Washington, 2004-2008.
 Mei-Yuh led the DARPA EARS and GALE Mandarin speech recongition projects
at University of Washington, and won the best Mandarin speech recognition in 2007.
    
<li> Speech recognition, Microsoft, Redmond WA, 1994-2004.
 Sphinx-II (see below) was ported to Microsoft on Windows desktop, Office, and Microsoft Speech Server SDK,
for the recognition of multiple languages. 
</ul>
  </table>
 
  <!--
<tr> Carnegie Mellon Univ <br> 1987-1993 <td> PhD student <td> SPHINX-II speech recognition 
 <ul>
 <li> Mei-Yuh was the first to propose
Markov state clustering, based on decision trees, for continuous speech recognition. 
  <li> The idea
of shared states (or
<a href="https://ieeexplore.ieee.org/document/225979/">senones</a> as Mei-Yuh named it in 1992) had
 been widely adopted for two decades since its inception, until recent years when end-to-end neural-transducer based speech 
 recognition and transformers took over a new era.
 </ul>
    
 <h3>Innovation</h3>
During all the years at industry, Mei-Yuh stays on top of research and works with researchers
side by side. She co-authored dozens of patents that she designed to solve practical
problems she encountered while delivering products. She stays active and contributive
to the research community.
Now she is combining all of her expertize
at <a href="http://www.mobvoi.com">Mobvoi</a> AI Lab 
-->

<h3>Awards</h3>
<ul>
 <li> 2021, <a href="https://www.aaia-ai.org/fellows?page=24">AAIA Fellow</a>
<li>2019, IEEE Fellow
<li> 2010, Microsoft Gold Star Award from Microsoft Research, Redmond, WA
<li> 1992, Allen Newell Research Excellence Medal, Pittsburgh, Carnegie Mellon University
<li> 1986, <a href="http://www.phitauphi.org.tw/">Phi Tao Phi Scholastic Honor Society</a>, recommended by National Taiwan University
</ul>

<h3>Professional Services</h3>
<ul>
<li> 2015-2018: IEEE ISCSLP steering committee
<li> 2013: IEEE associate editor for Transactions on Audio, Speech, and Language Processing (ASLP)
<li> 2011: Technical Chair of IWSLT
<li> 1998: Publicity Chair IEEE ICASSP
<li> Reviewers for IEEE Transactions on ASLP
<li> Technical committee for ICASSP, Interspeech, ISCSLP, ACL, NAACL</li>
</ul>

<h3> Invited Talks</h3>
<ul>
<li> 2020: WeCNLP Summit, Seattle online.
<li> 2019: Northwestern Polytechnical University, Xi-an, China
<li> 2018 April: Yuanchuan Telephony company, Taiwan
<li> 2017: <a href="https://www.youtube.com/watch?v=iVnBcGXBs3w">UWEE
Research Colloquium Talk</a>
<li> 2017: Panelist, <a href="https://cmu-summit.com/2017-sixth-summit/">
CMU Summit</a>
<li> 2017: Talk at Southwest Forestry Univerisity, Kunming, China
<li> 2017: Talk at Soochow University, Suzhou, China
<li> 2015: Talk at Soochow University, Suzhou, China
<li> 2014: Talk at University of Science and Technology of China, Suzhou campus
<li> 2014: Keynote speech at PhD Forum, Northwestern Polytechnical University, Xi-an, China
<li> 1994-2003: Lecturer at National Taiwan University, Academia Sinica, and ITRI, Taiwan
<li> 1993: Lecturer at IBM Gaithersburg
</ul>

<h3><a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mei-yuh+hwang&btnG=&oq=mei-yuh+hwang">Google Scholar</a></h3>
 
<h3>Education</h3>
<ul>
<li>PhD, Computer Science, Carnegie Mellon University, December 1993.
<!--
<ul>
Thesis: <a href="pub/1993/thesis.pdf">Subphonetic modeling for speech recogniton --- Senones</a>
</ul> -->
<li>BA, Computer Science, National Taiwan University, June 1986.
</ul>

<!--
<p>Mei-Yuh's <a href="index_files/children.htm">personal home page</a>
-->
</html>
