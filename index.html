<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body bgcolor="white">

<table>
<tr>
<!-- Hwang.jpg -->
 <td> <img src="datou.jpg" height=150>
 <td>Mei-Yuh Hwang <img src="name3.jpg" width=70>  <br> 
Affiliate Professor at EE Department<br> 
University of Washington  (UW) <br> <br>
mhwang at ee dot washington dot edu
 <td> <img src="empty.jpg" height=10>
<td> <img src="uw.jpg" width=80> <td> 
<!-- <img src="2018-logo.png" width=120> -->
</tr>
<tr>
<td> <br>
</tr>
</table>
  Mei-Yuh received her PhD in Computer Science from Carnegie Mellon
University in 1993 and had worked at Microsoft in U.S. and in China
for 18 years, publishing numerous conference and journal papers,
  and delivering industry products in speech recognition, machine
  translation, and language understanding. Additionally she spent four years at Uiniversity of Washington on Mandarin speech recognition for DARPA EARS and GALE projects
during 2004-2008, and four years at an AI startup, <a href="http://www.mobvoi.com">Mobvoi</a>, from 2016 through early 2020.
She is an IEEE fellow,
who is passionate in bridging the gap between academia and
industry. She is currently with <a href="https://www.microsoft.com/en-us/research/people/mehwang/">Microsoft MSAI </a> team.

<h3>Microsoft Search, Assistant, and Intelligence (MSAI), WA, 4/2020 </h3>
Enhance intelligence across Microsoft Office products, in search and assistants.


<h3>Mobvoi AI Lab, WA, 2016-2020</h3>
<p>
<a href="http://www.mobvoi.com">Mobvoi</a> makes speech-enabled 
smart <a href="http://store.ticwear.com">IoT
devices</a>, from hardware to software, all in-house.
<!-- , and is constantly
looking for <a href="hiring.html">AI experts</a>.-->
 Though a young company
that focuses on industry products, we are actively participating in
our speech research community with our limited resources. 
Our publications can be found in <a href="mobvoi/index.html#pub"> Mobvoi publications</a>.

<h3> Spoken language understanding for Cortana, Microsoft China, 2012-2015</h3>
To deliver non-English Cortana without human annotated data,
Mei-Yuh designed
an adapted translation algorithm which
offered both paraphrasing and generalization capabilities
with required slot tags. 
The protoype model was further improved via
 iterative data augmentation using RNN and newly logged data.
<!-- her team delivered six languages of Cortana
language understanding models with above 90% F1 scores.
-->
The impressive success of Chinese Cortana gained much attention within China, and sparked the development of 
personal assistants and AI across China.

<p>Mei-Yuh continued to contribute to Microsoft cognitive services:
<ul>
<li> Cortana non-English language
understanding for  <a href="https://azure.microsoft.com/en-us/services/cognitive-services/language-understanding-intelligent-service/">LUIS</a>, 
<li> Language-model adaptation for
<a href="https://azure.microsoft.com/en-us/services/cognitive-services/custom-speech-service/">customized speech recognition</a>.
<li> Spontaneous 
speech recogition for
<a href="https://www.techlicious.com/blog/skype-translator-preview-app-launch/">Skype speech-to-speech translation</a>.
</ul>


<!--
<p>Mei-Yuh received her PhD in Computer Science from Carnegie Mellon
University in December 1993, specializing in speech recongition. 
After graduation, she worked for Microsoft through 2004 in speech
research and products.
From 2004-2008 she joined University of Washington and led
the GALE Mandarin speech recognition project. 
In 2008 she returned to
Microsoft Research and was one of the core scientists behind
<a href="http://translate.bing.com">Bing Translator</a>.
From 2012-2015, she led speech recognition and language understanding
for non-English versions of Cortana in China, until she returned to
U.S. in 2016, leading Mobvoi AI Lab.

Over the past two decades,
Mei-Yuh has made many significant contributions to spoken language processing,
both in academia
and in industry. 
-->


<h3>Speech recognition and machine translation at Microsoft and UW, WA, 1994-2012</h3>
<p> Sphinx-II was ported to Microsoft on Windows desktop, Office, and Microsoft Speech Server SDK,
for the recognition of multiple languages during 1994-2004. 
<p> From 2004-2008, Mei-Yuh led the DARPA EARS and GALE Mandarin speech recongition projects
at University of Washington (UW). Her <a href="pub/2008/ASLP-IEEE/manuscript.pdf">IEEE paper</a> 
was a gold reference guide on building a strong Mandarin
speech recognizer.

<p>In 2008-2012, She co-built Bing Translator automated training infrastructure,
including the design and implementation of 
 map-reduce parallel processing, based on <a href="https://www.microsoft.com/en-us/research/project/dryadlinq/">DryadLink</a>.
She further designed and implemented
<a href="https://hub.microsofttranslator.com/">
 Bing Translation Hub</a> for customized vertical-domain translation.

<h3>SPHINX-II speech recognition at CMU, PA, 1987-1993</h3>
 Mei-Yuh was the first to propose
Markov state clustering based on decision trees for continuous speech recognition. The idea
of shared states (or
<a href="https://ieeexplore.ieee.org/document/225979/">senones</a> as Mei-Yuh named it in 1992) has been widely adopted for two decades since its inception, until recent years when end-to-end neural-based speech recognition such as RNN-T and transformers is gaining ground.

<!--
<h3>Innovation</h3>
During all the years at industry, Mei-Yuh stays on top of research and works with researchers
side by side. She co-authored dozens of patents that she designed to solve practical
problems she encountered while delivering products. She stays active and contributive
to the research community.
Now she is combining all of her expertize
at <a href="http://www.mobvoi.com">Mobvoi</a> AI Lab 
-->

<h3>Awards</h3>
<ul>
<!-- <li> 2016, China National 1000 Talents-->
<li>2019, IEEE Fellow
<li> 2010, Microsoft Gold Star Award from Microsoft Research, Redmond, WA
<li> 1992, Allen Newell Research Excellence Medal, Pittsburgh, Carnegie Mellon University
<li> 1986, <a href="http://www.phitauphi.org.tw/">Phi Tao Phi Scholastic Honor Society</a>, recommended by National Taiwan University
</ul>

<h3>Professional Services</h3>
<ul>
<li> 2015-2018: IEEE ISCSLP steering committee
<li> 2013: IEEE associate editor for Transactions on Audio, Speech, and Language Processing (ASLP)
<li> 2011: Technical Chair of IWSLT
<li> 1998: Publicity Chair IEEE ICASSP
<li> Reviewers for IEEE Transactions on ASLP
<li> Technical committee for ICASSP, Interspeech, ISCSLP, ACL, NAACL</li>
</ul>

<h3> Invited Talks</h3>
<ul>
<li> 2020: WeCNLP Summit, Seattle online.
<li> 2019: Northwestern Polytechnical University, Xi-an, China
<li> 2018 April: Yuanchuan Telephony company, Taiwan
<li> 2017: <a href="https://www.youtube.com/watch?v=iVnBcGXBs3w">UWEE
Research Colloquium Talk</a>
<li> 2017: Panelist, <a href="https://cmu-summit.com/2017-sixth-summit/">
CMU Summit</a>
<li> 2017: Talk at Southwest Forestry Univerisity, Kunming, China
<li> 2017: Talk at Soochow University, Suzhou, China
<li> 2015: Talk at Soochow University, Suzhou, China
<li> 2014: Talk at University of Science and Technology of China, Suzhou campus
<li> 2014: Keynote speech at PhD Forum, Northwestern Polytechnical University, Xi-an, China
<li> 1994-2003: Lecturer at National Taiwan University, Academia Sinica, and ITRI, Taiwan
<li> 1993: Lecturer at IBM Gaithersburg
</ul>

<h3><a href="https://scholar.google.com/citations?hl=en&user=I1Hr5-MAAAAJ">Google Scholar</a></h3>


<h3>Education</h3>
<ul>
<li>PhD, Computer Science, Carnegie Mellon University, December 1993.
<!--
<ul>
Thesis: <a href="pub/1993/thesis.pdf">Subphonetic modeling for speech recogniton --- Senones</a>
</ul> -->
<li>BA, Computer Science, National Taiwan University, June 1986.
</ul>

<!--
<p>Mei-Yuh's <a href="index_files/children.htm">personal home page</a>
-->
</html>

