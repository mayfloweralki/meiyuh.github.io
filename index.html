<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body bgcolor="white">
 <title> Mei-Yuh Hwang, speech recognition, machine translation, language understanding, scene-text OCR, GenAI </title>
 
<img src="datou.jpg" height=150> <br>
<h3> Mei-Yuh Hwang, IEEE Fellow</h3> 

<font size="-1"> <a href="https://www.ece.uw.edu/people/mei-yuh-hwang/">Affiliate Professor at EE Department </a> 
     </font> <br>
<font size="-1"> University of Washington  (UW) </font> <br>
  
<p> Mei-Yuh received her PhD in Computer Science from Carnegie Mellon University in 1993 and had worked at Microsoft in the U.S. 
  and in China for 20 years, publishing numerous conference and journal papers, and delivering industry products in 
  speech recognition, machine translation, and language understanding.

<p> Additionally she spent four years at University of Washington on Mandarin speech recognition and four years at an AI startup, Mobvoi, 
 focusing on AI smart watches and personal assistants. 
 Her focus has been always on turning state-of-the-art technologies into end-users' hands. 
 She is an IEEE fellow, who is passionate in bridging the gap between academia and industry.
 

 <h3> Meta, 5/2022--present </h3>
 <ul>
  <li> AI Research Scientist, Bellevue WA
  <li> <a href="https://en.wikipedia.org/wiki/Scene_text">Scene-Text OCR</a> and text-to-image generation.
</ul>
 
 <h3> Microsoft, 4/2020-4/2022</h3>
 <ul>
 <li> Partner science manager, Microsoft Search for Office 365, Bellevue WA.
<li> NLP for Outlook and Teams search, based on fine-tuning on, and/or few-shot prompting to, various large pre-trained language models.
 <li> Prompt engineering on GPT copilot to manipulate Excel spreadsheets.
</ul>
 
<h3>Mobvoi AI Lab, 2016-2020</h3>
 <ul>
 <li> Director, Redmond WA.
<li>
<a href="http://www.mobvoi.com">Mobvoi</a> makes speech-enabled 
smart IoT
devices</a>, from hardware to software, all in-house.
 <ul>
 <li> We are one of the most successful companies in <a href="http://store.ticwear.com">smart watches</a>. 
<li>  Mobvoi also provides the in-car voice assistant for VW automobiles in China.
 The technology includes both on-the-cloud and on-device voice navigation, enabling majority of services without internet connection.
<li> Though a young company
that focuses on industry products, we are actively participating in
our speech research community with our limited resources. 
 </ul>
<!-- Our publications can be found in <a href="mobvoi/index.html#pub"> Mobvoi publications</a>. -->
</ul>
 
<h3>Microsoft China,  2012-2015</h3>
 <ul>
 <li> Principal science manager, Spoken language understanding for Cortana, Beijing and Suzhou.
<li> Non-English Cortana
 <ul>
 <li> To deliver non-English Cortana without human annotated data,
Mei-Yuh designed
an adapted translation algorithm which
offered both paraphrasing and generalization capabilities
with required semantic slot tags. 
<li> The protoype model was further improved via
 iterative data augmentation using RNN and newly logged data.
 </ul>
 
 
<!-- her team delivered six languages of Cortana
language understanding models with above 90% F1 scores.
The impressive success of Chinese Cortana gained much attention within China, and sparked the development of 
personal assistants and AI across China. -->
 
  <li>Microsoft cognitive services on Azure cloud:
<ul>
<li> Cortana non-English language
understanding for  <a href="https://azure.microsoft.com/en-us/services/cognitive-services/language-understanding-intelligent-service/">LUIS</a>, 
<li> Language-model adaptation for
<a href="https://azure.microsoft.com/en-us/services/cognitive-services/custom-speech-service/">customized speech recognition</a>.
<li> Spontaneous 
speech recogition for
<a href="https://www.techlicious.com/blog/skype-translator-preview-app-launch/">Skype speech-to-speech translation</a>.
</ul>
</ul>


<h3>Microsoft and UW, 1994-2012</h3>
 <ul>
 <li> Machine translation, Microsoft, Redmond WA, 2008-2012.
  <ul>
<li>Co-built Bing Translator automated training infrastructure,
including the design and implementation of 
 map-reduce parallel processing, based on <a href="https://www.microsoft.com/en-us/research/project/dryadlinq/">DryadLink</a>.
<li>Designed and implemented
<a href="https://hub.microsofttranslator.com/">
 Bing Translation Hub</a> for customized vertical-domain translation.
  </ul>
  
 <li> Speech recognition at Univ. of Washington, 2004-2008.
  <ul> <li>
 Led the DARPA EARS and GALE Mandarin speech recongition projects
at University of Washington.
   <li> Won the best Mandarin speech recognition.
  </ul>


<li> Speech recognition, Microsoft Research & Production, Redmond WA, 1994-2004.
 <ul> <li>
 Ported Sphinx-II (see below) to Microsoft on Windows desktop, Office, and Microsoft Speech Server SDK,
for the recognition of multiple languages. 
</ul>
 </ul>
 
<h3>SPHINX-II speech recognition at CMU, PA, 1987-1993</h3>
 <ul>
 <li> First to propose
Markov state clustering, based on decision trees, for continuous speech recognition. 
  <li> The idea
of shared states (or
<a href="https://ieeexplore.ieee.org/document/225979/">senones</a> as Mei-Yuh named it in 1992) had
 been widely adopted for two decades since its inception, until recent years when end-to-end neural-transducer based 
  and transformer-based speech recognition took over a new era.
  <li> Participated in numerous DARPA speech recognition evaluation benchmarks (Resource Management, WSJ, ATIS) 
   and won the top position consistently.
 </ul>

<!--
<h3>Innovation</h3>
During all the years at industry, Mei-Yuh stays on top of research and works with researchers
side by side. She co-authored dozens of patents that she designed to solve practical
problems she encountered while delivering products. She stays active and contributive
to the research community.
Now she is combining all of her expertize
at <a href="http://www.mobvoi.com">Mobvoi</a> AI Lab 
-->

<h3>Awards</h3>
<ul>
 <li> 2021, <a href="https://www.aaia-ai.org/fellows?page=24">AAIA Fellow</a>
<li>2019, IEEE Fellow
<li> 2010, Microsoft Gold Star Award from Microsoft Research, Redmond, WA
<li> 1992, Allen Newell Research Excellence Medal, Pittsburgh, Carnegie Mellon University
<li> 1986, <a href="http://www.phitauphi.org.tw/">Phi Tao Phi Scholastic Honor Society</a>, recommended by National Taiwan University
</ul>

<h3>Professional Services</h3>
<ul>
<li> 2015-2018: IEEE ISCSLP steering committee
<li> 2013: IEEE associate editor for Transactions on Audio, Speech, and Language Processing (ASLP)
<li> 2011: Technical Chair of IWSLT
<li> 1998: Publicity Chair IEEE ICASSP
<li> Reviewers for IEEE Transactions on ASLP
<li> Technical committee for ICASSP, Interspeech, ISCSLP, ACL, NAACL</li>
</ul>

<h3> Invited Talks</h3>
<ul>
<li> 2020: WeCNLP Summit, Seattle online.
<li> 2019: Northwestern Polytechnical University, Xi-an, China
<li> 2018 April: Yuanchuan Telephony company, Taiwan
<li> 2017: <a href="https://www.youtube.com/watch?v=iVnBcGXBs3w">UWEE
Research Colloquium Talk</a>
<li> 2017: Panelist, <a href="https://cmu-summit.com/2017-sixth-summit/">
CMU Summit</a>
<li> 2017: Talk at Southwest Forestry Univerisity, Kunming, China
<li> 2017: Talk at Soochow University, Suzhou, China
<li> 2015: Talk at Soochow University, Suzhou, China
<li> 2014: Talk at University of Science and Technology of China, Suzhou campus
<li> 2014: Keynote speech at PhD Forum, Northwestern Polytechnical University, Xi-an, China
<li> 1994-2003: Lecturer at National Taiwan University, Academia Sinica, and ITRI, Taiwan
<li> 1993: Lecturer at IBM Gaithersburg
</ul>

<h3><a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mei-yuh+hwang&btnG=&oq=mei-yuh+hwang">Google Scholar</a></h3>
 
<h3>Education</h3>
<ul>
<li>PhD, Computer Science, Carnegie Mellon University, December 1993.
<!--
<ul>
Thesis: <a href="pub/1993/thesis.pdf">Subphonetic modeling for speech recogniton --- Senones</a>
</ul> -->
<li>BA, Computer Science, National Taiwan University, June 1986.
</ul>

<!--
<p>Mei-Yuh's <a href="index_files/children.htm">personal home page</a>
-->
</html>

